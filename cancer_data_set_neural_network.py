# -*- coding: utf-8 -*-
"""Cancer_data_set_neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tBZjuMB-na1pDIeMfImdq1ccfqb3f3p7
"""

from sklearn.datasets import load_breast_cancer

"""Loading and Reading Data"""

cancer_data = load_breast_cancer()

import pandas as pd
import numpy as np

df = pd.DataFrame(cancer_data.data,columns= cancer_data.feature_names)

df.head()

df.isnull().sum()

"""Creating Pandas Profiling report"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas_profiling as pp

profile = pp.ProfileReport(df)
profile.to_file('profile.html')

columns = list(df.columns)
columns

"""# Dimentionality Reduction..

Find the columns which are highly corelated with other and droping them from dataframe
"""

corr_columns = []
for i in range(0,29):
  for j in range(i,29):
    #print(columns[i],columns[j+1])
    corr_value = df[columns[i]].corr(df[columns[j+1]])
    # print(corr_value)
    if corr_value>=0.80:
      corr_columns.append(columns[j+1])
corr_columns = set(corr_columns)

corr_columns

df_new = df.drop(corr_columns,axis =1)

df_new.columns

df_new.head()

plt.figure(figsize=(10,10))
sns.heatmap(df_new.corr(),annot=True)
plt.show()

df_new.describe()

"""Treating Outliers"""

for i in df_new.columns:
  q1 = np.percentile(df_new[i],25)
  q3 = np.percentile(df_new[i],75)
  iqr = q3- q1
  ll = q1 - (1.5*iqr)
  ul = q3 + (1.5*iqr)
  for j in range(0,df_new.shape[0]):
    if df_new.loc[j,i] < ll:
      df_new.loc[j,i] = ll
    if df_new.loc[j,i] > ul:
      df_new.loc[j,i] = ul
    if df_new.loc[j,i] == 0.0:
      df_new.loc[j,i] = q1

df_new.describe()

sns.boxplot(df_new,orient ='h')

"""Making the data as normally distributed data using boxcox transformation"""

import scipy
from scipy.stats import boxcox

for i in df_new.columns:
  data,_= boxcox(df_new[i])
  df_new[i] = data

"""Min max scaling"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

df_scaled = scaler.fit_transform(df_new)
df_scaled = pd.DataFrame(df_scaled,columns = df_new.columns)
df_scaled.head()

sns.boxplot(df_scaled,orient ='h')

df_scaled.describe()

df.shape,df_scaled.shape

profile = pp.ProfileReport(df_scaled)
profile.to_file('profile_scaled.html')

for i in df_scaled.columns:
  plt.figure(figsize = (2,2))
  sns.kdeplot(df_scaled[i])
  plt.plot()

x = df_scaled

y  = pd.DataFrame(cancer_data.target, columns = ['result'])
y.head()

"""Spliting the data"""

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size= 0.2,stratify = y, random_state = 123)

"""Creation of neural network"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout

model = Sequential()
model.add(Dense(df_scaled.shape[1],activation = 'leaky_relu', input_shape = [x.shape[1],]))
model.add(Dropout(rate = 0.2))
model.add(Dense(5,activation = 'leaky_relu'))
model.add(Dropout(rate = 0.2))
model.add(Dense(5,activation = 'leaky_relu'))
model.add(Dropout(rate = 0.2))
model.add(Dense(1, activation  = 'sigmoid'))

model.summary()

model.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics ='accuracy' )

history = model.fit(x_train,y_train,epochs = 200,validation_data = (x_test,y_test))

plt.figure(figsize = (3,3))
plt.plot(history.history['loss'], label = ' Training Loss')
plt.plot(history.history['val_loss'], label = ' Valuation Loss')
plt.legend( )
plt.show

y_pred = np.round(model.predict(x_test),0)

"""Results and Accuracy understanding of the model"""

from sklearn.metrics import confusion_matrix, classification_report,accuracy_score

print(confusion_matrix(y_test,y_pred))

print(classification_report(y_test,y_pred))

print(accuracy_score(y_test,y_pred))